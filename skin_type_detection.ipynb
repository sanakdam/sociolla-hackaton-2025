{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04740404-20c7-441f-9707-c0c053133ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sociolla/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07aa7014-2239-42b2-b9b9-59d788c6395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 1️⃣ Define Enum for Skin Types\n",
    "# ===========================\n",
    "class SkinType(Enum):\n",
    "    NORMAL = 0\n",
    "    DRY = 1\n",
    "    OILY = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b09cee0-6496-43ce-aa40-5ea1f7208cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 2️⃣ Load & Preprocess Dataset\n",
    "# ===========================\n",
    "def load_dataset(dataset_path, batch_size=32, img_size=(224, 224)):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset_path,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='int'\n",
    "    )\n",
    "\n",
    "    # Store class names before applying transformations\n",
    "    print(\"Class names:\", dataset.class_names)\n",
    "\n",
    "    # Normalize pixel values\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "    # Data Augmentation Layer\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),\n",
    "        tf.keras.layers.RandomZoom(0.2)\n",
    "    ])\n",
    "\n",
    "    # Apply preprocessing\n",
    "    dataset = dataset.map(lambda x, y: (data_augmentation(normalization_layer(x)), y))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae9fcde-b85e-4953-841f-249154af5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 3️⃣ Split Dataset into Train & Validation Sets\n",
    "# ===========================\n",
    "def split_dataset(dataset, train_ratio=0.8):\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae721fed-bfcd-4d4c-bc61-20378819e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 4️⃣ Build CNN Model\n",
    "# ===========================\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(SkinType), activation='softmax')  # Enum-based classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f285ff-d046-4899-b52d-f8e45ea81c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 5️⃣ Train the Model\n",
    "# ===========================\n",
    "def train_model(model, train_dataset, val_dataset, epochs=10):\n",
    "    print(\"Training Model...\")\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=epochs)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573336b6-059b-459d-aabe-3986f23da408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 6️⃣ Save and Load Model\n",
    "# ===========================\n",
    "def save_model(model, model_path=\"skin_type_model.h5\"):\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved at {model_path}\")\n",
    "\n",
    "def load_trained_model(model_path=\"skin_type_model.h5\"):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "372d5cb6-8cdc-446e-9c76-79b3084bcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 7️⃣ Predict Skin Type from an Image\n",
    "# ===========================\n",
    "def preprocess_image(image_path, img_size=(224, 224)):\n",
    "    \"\"\"Converts a thermal image to a suitable format for the CNN.\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale (thermal)\n",
    "    image = cv2.applyColorMap(image, cv2.COLORMAP_JET)  # Apply thermal colormap\n",
    "    image = cv2.resize(image, img_size)  # Resize\n",
    "    image = np.expand_dims(image / 255.0, axis=0)  # Normalize\n",
    "\n",
    "    return image\n",
    "\n",
    "def extract_face_region(image_path, img_size=(224, 224)):\n",
    "    \"\"\"Extracts face region from an image using OpenCV's Haar Cascade.\"\"\"\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    # Read image and convert to grayscale\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(\"⚠️ No face detected! Using full image.\")\n",
    "        return preprocess_image(image_path, img_size)\n",
    "\n",
    "    # Crop the first detected face\n",
    "    x, y, w, h = faces[0]\n",
    "    face = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize and normalize\n",
    "    face = cv2.resize(face, img_size)\n",
    "    face = np.expand_dims(face / 255.0, axis=0)  # Normalize to (0-1)\n",
    "\n",
    "    return face\n",
    "\n",
    "def predict_skin_type(image_path, model):\n",
    "    image = extract_face_region(image_path)\n",
    "    prediction = model.predict(image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Get Enum name based on predicted index\n",
    "    predicted_skin_type = SkinType(predicted_class).name\n",
    "    print(f\"Predicted Skin Type: {predicted_skin_type}\")\n",
    "\n",
    "    # Show image\n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Predicted: {predicted_skin_tone}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe4212-5395-4a93-b21a-a39ccc107719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 8️⃣ Main Execution\n",
    "# ===========================\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"datasets/skin-type/\"  # Change this to your dataset path\n",
    "    dataset = load_dataset(dataset_path)\n",
    "    train_dataset, val_dataset = split_dataset(dataset)\n",
    "\n",
    "    model = build_model()\n",
    "    train_model(model, train_dataset, val_dataset)\n",
    "\n",
    "    save_model(model)  # Save after training\n",
    "\n",
    "    # Load model and test\n",
    "    model = load_trained_model()\n",
    "    predict_skin_type(\"test_image.jpeg\", model)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load model and test\n",
    "#     model = load_trained_model()\n",
    "#     predict_skin_tone(\"test_image3.jpg\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
